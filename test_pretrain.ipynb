{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from data.Dataset import MaskedDataset, MaskedDataset1, MaskedDataset2\n",
    "from data.DataModules import SSLDataModule\n",
    "from models import SSL_EEG\n",
    "from modules.decoders import MaskedDecoder\n",
    "from modules.loss import MaskedMSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to plot the reconstrution of the pretrained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = os.path.join(os.getcwd(), 'checkpoints')  \n",
    "prueba = os.path.join(checkpoints, 'SSL-1s-v5.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSL_EEG(\n",
       "  (encoder): TSTransformerEncoder(\n",
       "    (project_inp): Linear(in_features=8, out_features=64, bias=True)\n",
       "    (pos_enc): FixedPositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_layer): Linear(in_features=64, out_features=8, bias=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (covnet): Conv1DNet(\n",
       "    (conv1): Conv1d(8, 32, kernel_size=(32,), stride=(1,), padding=same)\n",
       "    (maxpool1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv1d(32, 64, kernel_size=(64,), stride=(1,), padding=same)\n",
       "    (maxpool2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (decoder): MaskedDecoder(\n",
       "    (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (linear2): Linear(in_features=32, out_features=8, bias=True)\n",
       "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SSL_EEG.load_from_checkpoint(prueba, decoder = MaskedDecoder, loss_fn= MaskedMSELoss)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = os.path.join(os.getcwd(), 'preprocess_data/tueh_mask_4s.h5')\n",
    "masked_dataset = MaskedDataset2(hdf5_file=eeg, normalize= 'normalization')\n",
    "# Create the data module with batch_size from wandb.config\n",
    "datamodule = SSLDataModule(dataset = masked_dataset,\n",
    "    batch_size=64,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the UVA dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c105651a5ea944399b3a1e109ee5f76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=7), IntSlider(value=0, description='j', max=99),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "\n",
    "@interact(i=IntSlider(min=0, max=7, step=1, value=0), j=IntSlider(min=0, max=99, step=1, value=0), continuous_update=False)\n",
    "def plote(i, j):\n",
    "    sample_uva = masked_dataset[j]\n",
    "    sample_uva_masked = sample_uva[0].unsqueeze(0)\n",
    "    sample_uva_raw = sample_uva[1].unsqueeze(0)\n",
    "    sample_uva_mask = sample_uva[2].unsqueeze(0)\n",
    "    output_encoder, _= model(sample_uva_masked.to(model.device))\n",
    "\n",
    "    # Define x, assuming 128 data points for each sample\n",
    "    x = np.linspace(0, 511, 512)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))  # Create a new figure for each plot\n",
    "\n",
    "    # Plot the raw data\n",
    "    plt.plot(x, sample_uva_raw[0, :, i].cpu().detach().numpy(), label='Raw EEG')\n",
    "    # Plot the mask\n",
    "    plt.plot(x, sample_uva_mask[0, :, i].cpu().detach().numpy(), label='Mask')\n",
    "    # Plot the prediction\n",
    "    plt.plot(x, output_encoder[0, :, i].cpu().detach().numpy(), label='Predicted')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(f'EEG Data Visualization for Channel {i+1} and Sample {j}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prove the model in another dataset different of the use for train. View the generalization of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_data = os.path.join(os.getcwd(), 'preprocess_data/deap_mask.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80640, 8, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brgonzalez/Escritorio/EEG_CHANEL/utils.py:39: RuntimeWarning: invalid value encountered in divide\n",
      "  apply_signal[:, :,j] = (apply_signal[:, :, j] - means) / (stds)\n"
     ]
    }
   ],
   "source": [
    "deap_masked_dataset = MaskedDataset1(hdf5_file=deap_data, normalize= 'normalization')\n",
    "# Create the data module with batch_size from wandb.config\n",
    "datamodule = SSLDataModule(dataset = deap_masked_dataset,\n",
    "    batch_size=64,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a7b7a67aea459ea993cc1ca966138d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=7), IntSlider(value=0, description='j', max=99),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "\n",
    "@interact(i=IntSlider(min=0, max=7, step=1, value=0), j=IntSlider(min=0, max=99, step=1, value=0), continuous_update=False)\n",
    "def plote(i, j):\n",
    "    sample_uva = deap_masked_dataset[j]\n",
    "    sample_uva_masked = sample_uva[0].unsqueeze(0)\n",
    "    sample_uva_raw = sample_uva[1].unsqueeze(0)\n",
    "    sample_uva_mask = sample_uva[2].unsqueeze(0)\n",
    "    output_encoder, _= model(sample_uva_masked.to(model.device))\n",
    "\n",
    "    # Define x, assuming 128 data points for each sample\n",
    "    x = np.linspace(0, 127, 128)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Create a new figure for each plot\n",
    "\n",
    "    # Plot the raw data\n",
    "    plt.plot(x, sample_uva_raw[0,:,i].cpu().detach().numpy(), label='Raw EEG')\n",
    "    # Plot the mask\n",
    "    #plt.plot(x, sample_uva_mask[0,:,i].cpu().detach().numpy(), label='Mask')\n",
    "    # Plot the prediction\n",
    "    plt.plot(x, output_encoder[0,:,i].cpu().detach().numpy(), label='Predicted')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(f'EEG Data Visualization for Channel {i+1} and Sample {j}')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
